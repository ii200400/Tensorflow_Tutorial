{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03.Linear Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtxe18NTnDqs5GEx2YhE7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ii200400/Tensorflow_Tutorial/blob/master/03%20-%20TensorFlow%20Basic/03_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFUmTaaDeu3i",
        "colab_type": "text"
      },
      "source": [
        "# 개요\n",
        "\n",
        "기초적인 선형 회귀 모델을 만들고 실행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZNVTCGjfHGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOul8rrAfH_x",
        "colab_type": "text"
      },
      "source": [
        "## 변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWwtFutgjAet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0f48f60a-c317-42ea-f6e8-98d3208efde7"
      },
      "source": [
        "x_data = [1, 2, 3]\n",
        "y_data = [1, 2, 3]\n",
        "\n",
        "# -1~1까지 균등분포(일정구간 내의 값들이 나타날 가능성이 동일한 분포)에서 값을 랜덤하게 추출한다.\n",
        "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "\n",
        "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여준다.\n",
        "X = tf.placeholder(tf.float32, name=\"X\")\n",
        "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"X:0\", dtype=float32)\n",
            "Tensor(\"Y:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z21yBuCsjFjT",
        "colab_type": "text"
      },
      "source": [
        "## 수식과 함수 생성 및 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP-P1eWTjU-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X 와 Y 의 상관 관계를 분석하기 위한 수식을 가정한다.\n",
        "# y = W * x + b\n",
        "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용하면 된다.\n",
        "hypothesis = W * X + b\n",
        "\n",
        "# 손실 함수를 작성한다.\n",
        "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정한다.\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행한다.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "# 비용을 최소화 하는 것이 최종 목표라고 설정을 해준다.\n",
        "train_op = optimizer.minimize(cost)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exttg81ljYwS",
        "colab_type": "text"
      },
      "source": [
        "## 그래프 생성과 실행 및 모델 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDn3---wnmf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b97578f1-06c6-4022-d034-447fd9b51556"
      },
      "source": [
        "# 세션을 생성하고 초기한다.\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # 최적화를 100번 수행한다.\n",
        "    for step in range(100):\n",
        "        # sess.run 을 통해 train_op 와 cost 그래프를 계산한다.\n",
        "        # 이 때, 가정한 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달한다.\n",
        "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
        "\n",
        "        print(step, cost_val, sess.run(W), sess.run(b))        \n",
        "\n",
        "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인한다.\n",
        "    print(\"\\n=== Test ===\")\n",
        "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
        "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 7.9178467 [1.3058685] [-0.371564]\n",
            "1 0.12005344 [1.1690168] [-0.4195986]\n",
            "2 0.025697293 [1.1791072] [-0.40328562]\n",
            "3 0.023417683 [1.1732547] [-0.39427137]\n",
            "4 0.022292668 [1.1692588] [-0.38471898]\n",
            "5 0.021233609 [1.1651715] [-0.3754787]\n",
            "6 0.020224975 [1.1612029] [-0.36645156]\n",
            "7 0.019264283 [1.1573274] [-0.3576424]\n",
            "8 0.01834921 [1.1535455] [-0.3490449]\n",
            "9 0.01747763 [1.1498543] [-0.34065413]\n",
            "10 0.016647419 [1.1462519] [-0.33246502]\n",
            "11 0.015856655 [1.1427361] [-0.32447278]\n",
            "12 0.015103442 [1.1393049] [-0.31667265]\n",
            "13 0.014386028 [1.135956] [-0.30906007]\n",
            "14 0.013702671 [1.1326878] [-0.30163047]\n",
            "15 0.0130517855 [1.129498] [-0.2943795]\n",
            "16 0.012431812 [1.126385] [-0.28730282]\n",
            "17 0.011841304 [1.1233468] [-0.28039625]\n",
            "18 0.011278822 [1.1203816] [-0.27365574]\n",
            "19 0.010743081 [1.1174877] [-0.26707724]\n",
            "20 0.010232765 [1.1146634] [-0.26065686]\n",
            "21 0.0097467 [1.111907] [-0.25439084]\n",
            "22 0.009283734 [1.1092168] [-0.24827547]\n",
            "23 0.008842747 [1.1065913] [-0.24230711]\n",
            "24 0.008422711 [1.1040289] [-0.23648223]\n",
            "25 0.0080226315 [1.1015282] [-0.23079737]\n",
            "26 0.007641547 [1.0990875] [-0.22524916]\n",
            "27 0.007278571 [1.0967054] [-0.21983431]\n",
            "28 0.0069328262 [1.0943807] [-0.21454962]\n",
            "29 0.006603508 [1.092112] [-0.20939198]\n",
            "30 0.006289827 [1.0898976] [-0.20435835]\n",
            "31 0.0059910677 [1.0877365] [-0.19944574]\n",
            "32 0.0057064816 [1.0856274] [-0.19465119]\n",
            "33 0.0054354225 [1.0835689] [-0.18997192]\n",
            "34 0.005177234 [1.08156] [-0.1854051]\n",
            "35 0.0049313167 [1.0795994] [-0.18094808]\n",
            "36 0.004697075 [1.0776858] [-0.17659822]\n",
            "37 0.004473953 [1.0758183] [-0.17235291]\n",
            "38 0.0042614373 [1.0739957] [-0.16820964]\n",
            "39 0.0040590297 [1.0722169] [-0.164166]\n",
            "40 0.0038662076 [1.0704808] [-0.16021955]\n",
            "41 0.0036825603 [1.0687866] [-0.15636796]\n",
            "42 0.0035076395 [1.067133] [-0.152609]\n",
            "43 0.0033410203 [1.0655191] [-0.14894038]\n",
            "44 0.0031823243 [1.0639441] [-0.14535995]\n",
            "45 0.0030311588 [1.0624069] [-0.1418656]\n",
            "46 0.0028871782 [1.0609066] [-0.13845523]\n",
            "47 0.0027500356 [1.0594425] [-0.13512684]\n",
            "48 0.0026194046 [1.0580136] [-0.13187848]\n",
            "49 0.0024949883 [1.0566189] [-0.12870821]\n",
            "50 0.0023764714 [1.0552579] [-0.12561414]\n",
            "51 0.0022635877 [1.0539294] [-0.12259448]\n",
            "52 0.0021560672 [1.052633] [-0.11964738]\n",
            "53 0.0020536496 [1.0513678] [-0.11677112]\n",
            "54 0.0019560924 [1.050133] [-0.113964]\n",
            "55 0.0018631788 [1.0489278] [-0.11122439]\n",
            "56 0.001774678 [1.0477517] [-0.10855062]\n",
            "57 0.0016903811 [1.0466037] [-0.10594117]\n",
            "58 0.0016100882 [1.0454834] [-0.10339441]\n",
            "59 0.0015336015 [1.04439] [-0.10090887]\n",
            "60 0.0014607599 [1.0433228] [-0.09848309]\n",
            "61 0.0013913695 [1.0422814] [-0.09611559]\n",
            "62 0.001325278 [1.041265] [-0.09380503]\n",
            "63 0.0012623254 [1.0402731] [-0.09155002]\n",
            "64 0.0012023601 [1.039305] [-0.08934923]\n",
            "65 0.0011452517 [1.03836] [-0.08720137]\n",
            "66 0.0010908496 [1.0374379] [-0.08510509]\n",
            "67 0.0010390333 [1.0365379] [-0.08305924]\n",
            "68 0.0009896798 [1.0356596] [-0.08106254]\n",
            "69 0.00094267057 [1.0348023] [-0.07911385]\n",
            "70 0.0008978885 [1.0339657] [-0.07721199]\n",
            "71 0.0008552417 [1.0331491] [-0.07535588]\n",
            "72 0.00081461715 [1.0323523] [-0.07354435]\n",
            "73 0.00077592285 [1.0315746] [-0.0717764]\n",
            "74 0.00073906354 [1.0308156] [-0.07005096]\n",
            "75 0.0007039598 [1.0300747] [-0.06836701]\n",
            "76 0.0006705226 [1.0293517] [-0.0667235]\n",
            "77 0.00063866953 [1.0286462] [-0.06511948]\n",
            "78 0.0006083337 [1.0279576] [-0.06355407]\n",
            "79 0.0005794383 [1.0272855] [-0.06202629]\n",
            "80 0.0005519115 [1.0266296] [-0.06053521]\n",
            "81 0.0005256985 [1.0259894] [-0.05908001]\n",
            "82 0.0005007234 [1.0253646] [-0.05765976]\n",
            "83 0.00047693984 [1.0247549] [-0.05627366]\n",
            "84 0.00045428425 [1.0241598] [-0.05492087]\n",
            "85 0.00043270524 [1.023579] [-0.05360059]\n",
            "86 0.00041215247 [1.0230122] [-0.05231207]\n",
            "87 0.00039257467 [1.022459] [-0.05105452]\n",
            "88 0.0003739288 [1.021919] [-0.04982724]\n",
            "89 0.00035616462 [1.0213922] [-0.04862939]\n",
            "90 0.00033924833 [1.020878] [-0.0474604]\n",
            "91 0.00032313567 [1.020376] [-0.04631951]\n",
            "92 0.00030778433 [1.0198861] [-0.045206]\n",
            "93 0.0002931648 [1.0194081] [-0.04411926]\n",
            "94 0.00027923624 [1.0189416] [-0.04305864]\n",
            "95 0.00026597476 [1.0184863] [-0.04202357]\n",
            "96 0.00025334055 [1.0180418] [-0.04101336]\n",
            "97 0.00024130817 [1.0176082] [-0.04002743]\n",
            "98 0.0002298454 [1.0171849] [-0.03906522]\n",
            "99 0.00021892949 [1.0167717] [-0.03812613]\n",
            "\n",
            "=== Test ===\n",
            "X: 5, Y: [5.0457325]\n",
            "X: 2.5, Y: [2.503803]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4umgv8WZgBor",
        "colab_type": "text"
      },
      "source": [
        "# 전체 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpPQ-gBLgAyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb0078f6-98f0-4ff7-af96-a1bd914842e4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_data = [1, 2, 3]\n",
        "y_data = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "\n",
        "X = tf.placeholder(tf.float32, name=\"X\")\n",
        "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "hypothesis = W * X + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train_op = optimizer.minimize(cost)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(100):\n",
        "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
        "\n",
        "        print(step, cost_val, sess.run(W), sess.run(b))\n",
        "\n",
        "    print(\"\\n=== Test ===\")\n",
        "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
        "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"X:0\", dtype=float32)\n",
            "Tensor(\"Y:0\", dtype=float32)\n",
            "0 1.4639992 [1.1087797] [-0.10795459]\n",
            "1 0.019901898 [1.0504338] [-0.12987556]\n",
            "2 0.0025371748 [1.0553125] [-0.12407395]\n",
            "3 0.0022205205 [1.0533171] [-0.12138415]\n",
            "4 0.0021127025 [1.0521082] [-0.11843415]\n",
            "5 0.002012316 [1.0508475] [-0.11559058]\n",
            "6 0.0019167326 [1.0496261] [-0.11281148]\n",
            "7 0.0018256836 [1.0484331] [-0.11009962]\n",
            "8 0.0017389682 [1.0472687] [-0.10745292]\n",
            "9 0.0016563629 [1.0461324] [-0.10486984]\n",
            "10 0.0015776838 [1.0450234] [-0.10234883]\n",
            "11 0.0015027443 [1.0439411] [-0.09988845]\n",
            "12 0.001431364 [1.0428848] [-0.09748722]\n",
            "13 0.0013633734 [1.0418539] [-0.09514371]\n",
            "14 0.0012986095 [1.0408478] [-0.09285653]\n",
            "15 0.0012369301 [1.0398657] [-0.09062434]\n",
            "16 0.0011781723 [1.0389074] [-0.08844577]\n",
            "17 0.0011222084 [1.0379721] [-0.08631957]\n",
            "18 0.0010689017 [1.0370593] [-0.0842445]\n",
            "19 0.0010181281 [1.0361685] [-0.08221933]\n",
            "20 0.00096976367 [1.035299] [-0.08024283]\n",
            "21 0.00092370296 [1.0344504] [-0.07831384]\n",
            "22 0.00087982323 [1.0336223] [-0.07643124]\n",
            "23 0.0008380324 [1.032814] [-0.07459389]\n",
            "24 0.0007982285 [1.0320251] [-0.07280073]\n",
            "25 0.00076031213 [1.0312552] [-0.07105063]\n",
            "26 0.0007241944 [1.030504] [-0.0693426]\n",
            "27 0.00068979507 [1.0297706] [-0.06767567]\n",
            "28 0.0006570297 [1.029055] [-0.06604879]\n",
            "29 0.0006258171 [1.0283566] [-0.06446102]\n",
            "30 0.0005960925 [1.0276748] [-0.06291144]\n",
            "31 0.0005677784 [1.0270095] [-0.06139907]\n",
            "32 0.0005408095 [1.0263603] [-0.05992305]\n",
            "33 0.0005151203 [1.0257266] [-0.05848256]\n",
            "34 0.00049064966 [1.0251081] [-0.05707667]\n",
            "35 0.00046734416 [1.0245045] [-0.05570457]\n",
            "36 0.00044514347 [1.0239155] [-0.05436546]\n",
            "37 0.00042400046 [1.0233406] [-0.05305858]\n",
            "38 0.000403858 [1.0227795] [-0.05178309]\n",
            "39 0.00038467612 [1.0222318] [-0.05053826]\n",
            "40 0.0003664029 [1.0216974] [-0.04932333]\n",
            "41 0.00034899754 [1.0211759] [-0.04813762]\n",
            "42 0.0003324208 [1.0206668] [-0.04698043]\n",
            "43 0.00031663178 [1.02017] [-0.04585109]\n",
            "44 0.00030159266 [1.019685] [-0.04474887]\n",
            "45 0.0002872657 [1.0192119] [-0.04367311]\n",
            "46 0.00027362167 [1.01875] [-0.04262325]\n",
            "47 0.0002606228 [1.0182993] [-0.04159858]\n",
            "48 0.0002482427 [1.0178593] [-0.0405986]\n",
            "49 0.00023645023 [1.0174301] [-0.0396226]\n",
            "50 0.0002252196 [1.017011] [-0.03867012]\n",
            "51 0.00021452065 [1.0166022] [-0.03774051]\n",
            "52 0.00020433292 [1.0162029] [-0.03683328]\n",
            "53 0.00019462539 [1.0158135] [-0.0359478]\n",
            "54 0.00018538132 [1.0154333] [-0.03508363]\n",
            "55 0.00017657562 [1.0150623] [-0.03424023]\n",
            "56 0.00016818725 [1.0147003] [-0.03341712]\n",
            "57 0.00016019648 [1.014347] [-0.0326138]\n",
            "58 0.00015258849 [1.014002] [-0.03182982]\n",
            "59 0.00014534169 [1.0136653] [-0.03106465]\n",
            "60 0.00013843666 [1.0133369] [-0.03031785]\n",
            "61 0.0001318615 [1.0130162] [-0.02958904]\n",
            "62 0.00012559826 [1.0127033] [-0.02887772]\n",
            "63 0.0001196306 [1.012398] [-0.02818349]\n",
            "64 0.00011394851 [1.0120999] [-0.027506]\n",
            "65 0.00010853587 [1.0118091] [-0.02684474]\n",
            "66 0.00010338048 [1.0115252] [-0.02619944]\n",
            "67 9.8470606e-05 [1.0112481] [-0.02556962]\n",
            "68 9.379222e-05 [1.0109777] [-0.02495493]\n",
            "69 8.933651e-05 [1.0107138] [-0.02435504]\n",
            "70 8.5094325e-05 [1.0104562] [-0.02376956]\n",
            "71 8.1051854e-05 [1.0102049] [-0.02319813]\n",
            "72 7.720205e-05 [1.0099596] [-0.02264048]\n",
            "73 7.353375e-05 [1.0097202] [-0.02209621]\n",
            "74 7.0041184e-05 [1.0094866] [-0.02156505]\n",
            "75 6.671431e-05 [1.0092585] [-0.02104666]\n",
            "76 6.3545645e-05 [1.009036] [-0.02054073]\n",
            "77 6.0526774e-05 [1.0088187] [-0.02004696]\n",
            "78 5.7652844e-05 [1.0086067] [-0.01956508]\n",
            "79 5.4913984e-05 [1.0083998] [-0.01909473]\n",
            "80 5.230487e-05 [1.0081979] [-0.01863571]\n",
            "81 4.982115e-05 [1.0080009] [-0.01818774]\n",
            "82 4.74546e-05 [1.0078084] [-0.01775053]\n",
            "83 4.520018e-05 [1.0076208] [-0.01732381]\n",
            "84 4.3053577e-05 [1.0074376] [-0.01690737]\n",
            "85 4.100766e-05 [1.0072588] [-0.01650092]\n",
            "86 3.9059993e-05 [1.0070844] [-0.01610423]\n",
            "87 3.720495e-05 [1.006914] [-0.01571713]\n",
            "88 3.5437846e-05 [1.0067478] [-0.01533931]\n",
            "89 3.3754677e-05 [1.0065856] [-0.01497059]\n",
            "90 3.2151376e-05 [1.0064273] [-0.01461072]\n",
            "91 3.0623905e-05 [1.0062728] [-0.01425949]\n",
            "92 2.9168948e-05 [1.006122] [-0.0139167]\n",
            "93 2.7783588e-05 [1.0059749] [-0.01358215]\n",
            "94 2.6464344e-05 [1.0058311] [-0.01325568]\n",
            "95 2.5206848e-05 [1.005691] [-0.01293699]\n",
            "96 2.4009554e-05 [1.0055542] [-0.012626]\n",
            "97 2.2869397e-05 [1.0054207] [-0.01232249]\n",
            "98 2.1783017e-05 [1.0052904] [-0.01202627]\n",
            "99 2.07478e-05 [1.0051632] [-0.01173716]\n",
            "\n",
            "=== Test ===\n",
            "X: 5, Y: [5.0140786]\n",
            "X: 2.5, Y: [2.5011709]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}