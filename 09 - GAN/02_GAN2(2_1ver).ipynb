{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.GAN2(2.1ver).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqAD/nGHUzpu8qA31ginVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ii200400/Tensorflow_Tutorial/blob/master/09%20-%20GAN/02_GAN2(2_1ver).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHFARydlSjmj",
        "colab_type": "text"
      },
      "source": [
        "# 개요\n",
        "\n",
        "GAN 모델을 이용하여 원하는 손글씨 숫자를 생성하는 모델을 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4EO2rwVS5KL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd889c88-07fc-42f0-d92d-4f077a22689e"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTpyzul7THk_",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTMq0jibTMIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28*28).astype('float32') / 255\n",
        "y_train = tf.one_hot(y_train, depth=10).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odkGwFnxbYDF",
        "colab_type": "text"
      },
      "source": [
        "## 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m1c2nVrXu7Z",
        "colab_type": "text"
      },
      "source": [
        "### 옵션 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM8Sq4cgYhV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden = 256\n",
        "n_input = 28 * 28\n",
        "n_noise = 128\n",
        "n_class = 10\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "buffer_size = 60000\n",
        "learning_rate = 0.0002"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78AIJYP5bjEZ",
        "colab_type": "text"
      },
      "source": [
        "### 신경망 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZriQVSblcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "c0cd5c18-787c-4374-8959-a435a3c3dffe"
      },
      "source": [
        "# 처음에 만든 신경망과 크게 다르지 않다. 라벨 정보가 들어갈 \n",
        "\n",
        "# 생성기(G) 모델 신경망\n",
        "def generator():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(n_hidden, activation='relu', input_shape=(n_noise+n_class,)),\n",
        "    tf.keras.layers.Dense(n_input, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 판별기(G) 모델 신경망\n",
        "def discriminator():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(n_hidden, activation='relu', input_shape=(n_input+n_class,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "G = generator()\n",
        "D = discriminator()\n",
        "\n",
        "G.summary()\n",
        "D.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               35584     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 784)               201488    \n",
            "=================================================================\n",
            "Total params: 237,072\n",
            "Trainable params: 237,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 256)               203520    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 203,777\n",
            "Trainable params: 203,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COPajB5BBEvX",
        "colab_type": "text"
      },
      "source": [
        "### 손실 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZS7jkvtBHAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# 생성기(G) 손실 함수\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# 판별기(D) 손실 함수\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  return real_loss + fake_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BADBM6dhTBC9",
        "colab_type": "text"
      },
      "source": [
        "### 최적화 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tc23XZXTE1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUb4_hFSaCKy",
        "colab_type": "text"
      },
      "source": [
        "### 모델 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFQO0CdkaEZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 학습 함수\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  # 임의의 \n",
        "  noise = tf.random.normal([batch_size, n_noise])\n",
        "  noise = tf.concat([noise, labels], axis=1)\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = G(noise, training=True)\n",
        "\n",
        "    real_output = D(tf.concat([images, labels], axis=1), training=True)\n",
        "    fake_output = D(tf.concat([generated_images, labels], axis=1), training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gen_gradient = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
        "  disc_gradient = disc_tape.gradient(disc_loss, D.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gen_gradient, G.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(disc_gradient, D.trainable_variables))\n",
        "\n",
        "  return (gen_loss, disc_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4jRbVLmIvrr",
        "colab_type": "text"
      },
      "source": [
        "### 이미지 출력 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnxwZLLiIw0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#이미지 출력 함수\n",
        "def show_images(test_image):\n",
        "  input_size = len(test_image)\n",
        "\n",
        "  predictions = G(test_image, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(input_size, 1))\n",
        "  for i in range(input_size):\n",
        "    plt.subplot(1, input_size, i+1)\n",
        "    plt.imshow(tf.reshape(predictions[i], (28, 28)))\n",
        "    plt.axis('off')\n",
        "    plt.title(str(tf.math.argmax(test_image.numpy()[i][128:]).numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uzNL36PoG3X",
        "colab_type": "text"
      },
      "source": [
        "### 모델 학습 및 이미지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEZdvop0oIm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples_to_generate = 16\n",
        "\n",
        "# 데이터를 섞고 배치크기로 나눠준다.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size).batch(batch_size)\n",
        "train_dataset = list(train_dataset.as_numpy_iterator())\n",
        "\n",
        "y_test = y_train[:num_examples_to_generate]\n",
        "test_noise = tf.random.normal([num_examples_to_generate, n_noise])\n",
        "test_noise = tf.concat([test_noise, y_test], 1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch:', '%04d' % (epoch+1))\n",
        "  for data in train_dataset:\n",
        "    gen_loss, disc_loss = train_step(data[0], data[1])\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    show_images(test_noise)\n",
        "\n",
        "  print('D loss: {:.4}'.format(disc_loss),\n",
        "        'G loss: {:.4}'.format(gen_loss))\n",
        "\n",
        "show_images(test_noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIm3dURshqlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "fdc8e877-ace5-428c-ee61-7966a9b10b10"
      },
      "source": [
        "noise = np.random.uniform(-1., 1., size=[10, 10])\n",
        "labels = [[0,0,0,0,0,0,0,0,0,1] for _ in range(10)]\n",
        "inputs = tf.concat([noise, labels], 1)\n",
        "print(inputs[0])\n",
        "asd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.06426246 -0.34010086 -0.11410678  0.73011312 -0.1391853  -0.74418949\n",
            "  0.00174777 -0.19019187  0.84862746 -0.1546649   0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          1.        ], shape=(20,), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4cbdd0bda770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0masd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'asd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0jeqE8Q62HB",
        "colab_type": "text"
      },
      "source": [
        "## 전체 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRvcqfP1NWnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28*28).astype('float32') / 255\n",
        "y_train = tf.one_hot(y_train, depth=10).numpy()\n",
        "\n",
        "#########\n",
        "# 옵션 설정\n",
        "######\n",
        "\n",
        "n_hidden = 256\n",
        "n_input = 28 * 28\n",
        "n_noise = 128\n",
        "n_class = 10\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 100\n",
        "buffer_size = 60000\n",
        "learning_rate = 0.0002\n",
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "######\n",
        "\n",
        "# 생성기(G) 모델 신경망\n",
        "def generator():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(n_hidden, activation='relu', input_shape=(n_noise+n_class,)),\n",
        "    tf.keras.layers.Dense(n_input, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 판별기(G) 모델 신경망\n",
        "def discriminator():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(n_hidden, activation='relu', input_shape=(n_input+n_class,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "G = generator()\n",
        "D = discriminator()\n",
        "\n",
        "# G.summary()\n",
        "# D.summary()\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# 생성기(G) 손실 함수\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# 판별기(D) 손실 함수\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  return real_loss + fake_loss\n",
        "\n",
        "# 최적화 설정\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "\n",
        "# 모델 학습 함수\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  noise = tf.random.normal([batch_size, n_noise])\n",
        "  noise = tf.concat([noise, labels], axis=1)\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = G(noise, training=True)\n",
        "\n",
        "    real_output = D(tf.concat([images, labels], axis=1), training=True)\n",
        "    fake_output = D(tf.concat([generated_images, labels], axis=1), training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gen_gradient = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
        "  disc_gradient = disc_tape.gradient(disc_loss, D.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gen_gradient, G.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(disc_gradient, D.trainable_variables))\n",
        "\n",
        "  return (gen_loss, disc_loss)\n",
        "\n",
        "#이미지 출력 함수\n",
        "def show_images(test_image):\n",
        "  input_size = len(test_image)\n",
        "\n",
        "  predictions = G(test_image, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(input_size, 1))\n",
        "  for i in range(input_size):\n",
        "    plt.subplot(1, input_size, i+1)\n",
        "    plt.imshow(tf.reshape(predictions[i], (28, 28)))\n",
        "    plt.axis('off')\n",
        "    plt.title(str(tf.math.argmax(test_image.numpy()[i][128:]).numpy()))\n",
        "\n",
        "# 모델 학습 및 이미지 확인\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size).batch(batch_size)\n",
        "train_dataset = list(train_dataset.as_numpy_iterator())\n",
        "\n",
        "y_test = y_train[:num_examples_to_generate]\n",
        "test_noise = tf.random.normal([num_examples_to_generate, n_noise])\n",
        "test_noise = tf.concat([test_noise, y_test], 1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch:', '%04d' % (epoch+1))\n",
        "  for data in train_dataset:\n",
        "    gen_loss, disc_loss = train_step(data[0], data[1])\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    show_images(test_noise)\n",
        "\n",
        "  print('D loss: {:.4}'.format(disc_loss),\n",
        "        'G loss: {:.4}'.format(gen_loss))\n",
        "\n",
        "show_images(test_noise)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}