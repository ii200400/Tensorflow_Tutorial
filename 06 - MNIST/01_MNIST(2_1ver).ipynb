{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01.MNIST(2.1ver).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrqBDUW2nG1tBg5NASiI+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ii200400/Tensorflow_Tutorial/blob/master/06%20-%20MNIST/01_MNIST(2_1ver).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtgoQPg5sYFt",
        "colab_type": "text"
      },
      "source": [
        "# 개요\n",
        "\n",
        "MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어보자!\n",
        "\n",
        "참고\\\n",
        "https://www.tensorflow.org/tutorials/quickstart/beginner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJasTZIHtH_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W26K6xaTtHCS",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 정의\n",
        "\n",
        "MNIST는 기본적으로 케라스 함수에서 불러올 수 있는데 그점을 이용하여 코딩을 할 것이다.\n",
        "\n",
        "x_train의 크기는 [이미지 수, 세로 픽셀 수, 가로 픽셀 수] -> [60000, 28, 28]\\\n",
        "y_train의 크기는 [이미지 수] -> [60000]\n",
        "\n",
        "y_train의 각 요소는 0~9이며 이전과 같은 one-hot 인코딩이 아닌 정수 인코딩으로 표현된다.\\\n",
        " one-hot -- integer\\\n",
        "[0,0,0,0,1] -- [5]\\\n",
        "[0,1,0,0,0] -- [2]\\\n",
        "[0,0,0,1,0] -- [4]\n",
        "\n",
        "때문에 one-hot 인코딩방식으로 전환하는 코드를 사용하였다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dtmJl_ftLPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3e8f20e6-f1ab-40dc-936a-b8e7b026256f"
      },
      "source": [
        "# MNIST 데이터셋을 케라스 함수로 받아온다.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 샘플 값을 정수에서 부동소수로 변환한다.\n",
        "# 원래는 gray_color로 0~255사이의 값으로 정수로 저장되어 있는데 \n",
        "# 모델 내에서 계산할 때에는 0~1 사이의 소수가 필요하기 때문이다.\n",
        "# 동시에 [60000,28,28] 형태의 이미지를 [60000, 784]으로 flattening 한다.\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "# 레이블 데이터에 one-hot encoding을 적용한다.\n",
        "y_train, y_test = tf.one_hot(y_train, depth=10).numpy(), tf.one_hot(y_test, depth=10).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj82EN_c_WHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ef162cce-1c74-4557-be60-be86b6477bdf"
      },
      "source": [
        "print(x_train[:3])\n",
        "print(y_train[:3])\n",
        "print(len(x_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "60000\n",
            "60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8HS1gcHtLva",
        "colab_type": "text"
      },
      "source": [
        "## 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y22K9fiH27_D",
        "colab_type": "text"
      },
      "source": [
        "### 신경망 구성\n",
        "\n",
        "케라스 함수로 만든 layer함수의 API들은 여러 옵션을 통하여 편리성을 더한다.\n",
        "\n",
        "기본적으로 가중치는 자동으로 초기화가 되며 사용자가 신경쓰지 않아도 되고 \\\n",
        "편향은 쓸지 안 쓸지의 여부만 옵션으로 전달해주는 등 \\\n",
        "잘 알고 쓰면 몇 줄 안되는 코드로 복잡한 신경망을 구성할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzWV93HpuZzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 텐서플로우의 케라서에서 제공하는 모델 함수를 사용하여 모델을 작성한다.\n",
        "# 신경망의 레이어는 다음처럼 구성한다.\n",
        "# 784(입력 특성값)\n",
        "#   -> 256 (히든레이어 뉴런 갯수) -> 256 (히든레이어 뉴런 갯수)\n",
        "#   -> 10 (결과값 0~9 분류)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, activation=tf.nn.relu, use_bias=False),  # 뉴런 수가 256개인 히든 레이어 생성\n",
        "  tf.keras.layers.Dense(256, activation=tf.nn.relu, use_bias=False),\n",
        "  tf.keras.layers.Dense(10, activation='softmax', use_bias=False)     # 결과값이 10가지가 되도록 하는 레이어\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFq1McnM3CQd",
        "colab_type": "text"
      },
      "source": [
        "### 최적화 / 손실 클래스 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUP7GDMw_S5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 최적화 함수는 adam\n",
        "# 손실함수는 one-hot 인코딩에 알맞은 비용함수 categorical_crossentropy를 사용한다.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC237U0uCBtE",
        "colab_type": "text"
      },
      "source": [
        "### 모델 훈련  및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aooBBBkdCG2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "64746603-ccd7-441f-9b64-e22b6dbe12bd"
      },
      "source": [
        "# epoch 크기는 15, batch 크기는 100으로 한다.\n",
        "epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "# 모델을 훈련한다.\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# 모델을 테스트 해본다.\n",
        "model.evaluate(x_test,  y_test, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 1.4657 - accuracy: 0.9961\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 1.4660 - accuracy: 0.9955\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 1.4651 - accuracy: 0.9966\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 1.4660 - accuracy: 0.9955\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 1.4651 - accuracy: 0.9965\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 1.4640 - accuracy: 0.9974\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 1.4647 - accuracy: 0.9968\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 1.4650 - accuracy: 0.9963\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 1.4646 - accuracy: 0.9968\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 1.4639 - accuracy: 0.9974\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 1.4654 - accuracy: 0.9961\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 1.4646 - accuracy: 0.9967\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 1.4647 - accuracy: 0.9966\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 1.4643 - accuracy: 0.9969\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 1.4645 - accuracy: 0.9969\n",
            "10000/10000 - 0s - loss: 1.4799 - accuracy: 0.9812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4798706030845643, 0.9812]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9GjHnr6sga4",
        "colab_type": "text"
      },
      "source": [
        "# 전체 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkR4WTGPkDWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "6823edee-6a4b-4bdc-a918-9d9fdbf0f233"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "y_train, y_test = tf.one_hot(y_train, depth=10).numpy(), tf.one_hot(y_test, depth=10).numpy()\n",
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "######\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, activation=tf.nn.relu),  # 뉴런 수가 256개인 히든 레이어 생성\n",
        "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')     # 결과값이 10가지가 되도록 하는 레이어\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "#########\n",
        "# 결과 확인\n",
        "######\n",
        "\n",
        "model.evaluate(x_test,  y_test, batch_size=batch_size, verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2451 - accuracy: 0.9281\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0903 - accuracy: 0.9724\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0607 - accuracy: 0.9809\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0439 - accuracy: 0.9861\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0318 - accuracy: 0.9900\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0255 - accuracy: 0.9915\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0229 - accuracy: 0.9929\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0162 - accuracy: 0.9948\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0162 - accuracy: 0.9947\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0129 - accuracy: 0.9954\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0136 - accuracy: 0.9956\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0113 - accuracy: 0.9961\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0112 - accuracy: 0.9962\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0122 - accuracy: 0.9958\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0072 - accuracy: 0.9975\n",
            "10000/10000 - 0s - loss: 0.1141 - accuracy: 0.9772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11410180909082257, 0.9772]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}